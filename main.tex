%-*- program: xelatex -*-        
%-*- program: biber -*-        
%-*- program: xelatex -*-

\documentclass[
    sigplan,
    10pt,
    review, % Note: remove the [review] option for the final document.
    natbib=false % Note: This ishere to be able to use Biber.
 ]{acmart}
%\let\citename\relax

\settopmatter{printfolios=true,printccs=false,printacmref=false}

\acmConference[DLS'18]{Dynamic Languages Symposium}{November~6, 2018}{Boston, MA, USA}
\acmYear{2018}
\acmISBN{} % \acmISBN{978-x-xxxx-xxxx-x/YY/MM}
\acmDOI{} % \acmDOI{10.1145/nnnnnnn.nnnnnnn}
\startPage{1}

\setcopyright{none}

\bibliographystyle{ACM-Reference-Format}

\usepackage{booktabs}
\usepackage{subcaption}

\usepackage[
   backend=biber,
   bibencoding=utf8,
   style=numeric,
   hyperref=true,
   % citestyle=authoryear-comp,
   backref=false,
   sortlocale=en,
   url=true,
   doi=false,
   eprint=false
 ]{biblatex}
\addbibresource{biblio.bib}

\usepackage{minted}
\setminted{encoding=utf8,fontsize=\small,breaklines}

\usepackage{tikz}
\usetikzlibrary{positioning}

\tikzset{
	box/.style = { 
		draw = black,
        fill = white,
		rectangle,
		rounded corners = 2pt,
		text centered,
		minimum height = 5mm,
		minimum width = 10mm
	}
}

\usepackage{todonotes}
\newcommand\mb[1]{\todo[color=purple!20,size=\scriptsize]{#1}}
\newcommand\mbi[1]{\todo[color=purple!20,inline]{#1}}
\newcommand\et[1]{\todo[color=blue!20,size=\scriptsize]{#1}}
\newcommand\eti[1]{\todo[color=blue!20,inline]{#1}}

\setlength{\marginparwidth}{15mm} % Note: This is only temporary, to have notes more readable. It should be removed before submitting.

\newcommand\ignore[1]{}

\newcommand\CoqR{CoqR}

\begin{document}

\title{A Trustworthy Formalization of R} % I didn't thought much about this. Any suggestion?

\author{Martin Bodin}
\orcid{0000-0003-3588-3782}
\affiliation{
  %\position{}
  \department{Center for Mathematical Modeling}
  \institution{University of Chile}
  \streetaddress{Beauchef 851}
  \city{Santiago}
  % \state{State1}
  % \postcode{Post-Code1}
  \country{Chile}
}
\email{mbodin@dim.uchile.cl}

\author{Tom{\'a}s Diaz}
% \authornote{with author2 note}
% \orcid{nnnn-nnnn-nnnn-nnnn}
\affiliation{
  % \position{Position2a}
  \department{Computer Science Department}
  \institution{University of Chile}
  \streetaddress{Beauchef 851}
  \city{Santiago}
  % \state{State2a}
  % \postcode{Post-Code2a}
  \country{Chile}
}
\email{tdiaz@dcc.uchile.cl}

\author{{\'E}ric Tanter}
% \authornote{with author2 note}
% \orcid{nnnn-nnnn-nnnn-nnnn}
\affiliation{
  % \position{Position2a}
  \department{Computer Science Department}
  \institution{University of Chile}
  \streetaddress{Beauchef 851}
  \city{Santiago}
  % \state{State2a}
  % \postcode{Post-Code2a}
  \country{Chile}
}
\email{etanter@dcc.uchile.cl}

\begin{abstract}
\eti{update when paper is stable:}

    The R programming language is used by a large community.
    Yet, its semantics contains subtle but various corner-cases.
    This makes it difficult to fully trust an R program,
    as these corner-cases can lead to unexpected behavior.
    We believe that a Coq formalization of the language would help.

    We introduce \CoqR{}, an R interpreter written in Coq.
    This interpreter has been related to the reference R interpreter
    GNU~R by two ways.
    First, the Coq code has been written to mimic the source code of GNU~R.
    Second, the interpreter has been extensively tested against GNU~R.
    Both these methods helped finding bugs.

    We have furthermore developed a general testing architecture
    for R interpreters.
    It guided our Coq development
    and we believe that it can be reused by other interpreters.
\end{abstract}

% % %% 2012 ACM Computing Classification System (CSS) concepts
% % %% Generate at 'http://dl.acm.org/ccs/ccs.cfm'.
% \begin{CCSXML}
%   <ccs2012>
%     <concept>
%       <concept_id>10003752.10010124.10010131.10010133</concept_id>
%       <concept_desc>Theory of computation~Denotational semantics</concept_desc>
%       <concept_significance>500</concept_significance>
%     </concept>
%     <concept>
%       <concept_id>10011007.10011006.10011066.10011070</concept_id>
%       <concept_desc>Software and its engineering~Application specific development environments</concept_desc>
%       <concept_significance>300</concept_significance>
%     </concept>
%     <concept>
%       <concept_id>10011007.10011074.10011099.10011692</concept_id>
%       <concept_desc>Software and its engineering~Formal software verification</concept_desc>
%       <concept_significance>100</concept_significance>
%     </concept>
%   </ccs2012>
% \end{CCSXML}

% \ccsdesc[500]{Theory of computation~Denotational semantics}
% \ccsdesc[300]{Software and its engineering~Application specific development environments}
% \ccsdesc[100]{Software and its engineering~Formal software verification}
% % %% End of generated code

% \keywords{R, Coq, Formalization, Testing}

\maketitle

\section{Introduction}
\label{sec:intro}

% R is used a lot.
The R programming language~\parencite{R, ihaka1996r, Rwebsite}
has gotten a lot of traction in recent years, being used by millions of users in areas as varied as biology and finance. This diversity among R programmers results in largely different programming styles. In fact, the language itself is community driven and reflects this diversity.
% R is complex and we need to certify R softwares.
The R programming language is meant to be both expressive and powerful,
able to express complex notions in few keystrokes.
This sometimes comes at the cost of readability and predictability. Indeed, 
the semantics of R is subtle and contains numerous corner cases that can result in unexpected behavior. 

The reasons for these corner cases are numerous, ranging from backward compatibility to the desire to accommodate the use of R as both a traditional programming language and an interactive shell.
Even a feature as basic as function calls can be the source of surprises in R. 
Indeed, there are many ways to call a function, and in particular there are two ways to provide an argument: either by position or by name.\footnote{
    To simplify, we ignore the \mintinline{R}{...} construct
    as well as default arguments, which both have non-trivial interactions with the other constructs.} While this per se is fairly common, the way R supports it is not; in particular it supports matching names {\em by prefix}. 
% 
To illustrate some subtleties that follow from this feature, 
Figure~\ref{fig:calls} defines a function \mintinline{R}{f} that concatenates its three arguments. The first call associates arguments by position, and the second by name. The third call mixes both mechanisms, and exploits the prefix feature: \mintinline{R}{d} is associated to \mintinline{R}{de}
because it is the only argument whose name starts with \mintinline{R}{d}.
Now, if more than one argument matches by prefix,
then R rejects the call and throws an error,
as in the fifth call in Figure~\ref{fig:calls}.
However, exact matches are not counted in this process:
in the fourth call,
the name \mintinline{R}{ab} is an exact match
and thus only the argument \mintinline{R}{abc}
is left to be associated to \mintinline{R}{a},
leading to no error thrown.

\begin{figure}[t]
\begin{minted}{R}
f <- function (abc, ab, de) { c (abc, ab, de) }
f(1, 2, 3)           # By position
f(de=3, abc=1, ab=2) # By name
f(1, d=3, 2)         # Mixed
f(3, a=1, ab=2)      # a is associated to abc
f(a=3, 1, 2)         # error: several prefixes
\end{minted}
\caption{Exploring function calls in R.}
\label{fig:calls}
\end{figure}

Such subtle behaviors are numerous in R~\parencite{RInferno}.
Debugging tools exist~\parencite{mcpherson2014},
but they cannot always compensate for the complex semantics of R.
Consequently, surprising bugs occur in R programs
and fully trusting such programs can be difficult.
%
% We need a formalization of the language.
Formal methods offer a solution to the trust issue:
proof assistants such as Coq~\parencite{Coq} enable us
to formally prove program properties with a high amount of trust.
But to formally prove that an R program meets its specification,
we first need a formal semantics of R. While there exists a language definition document~\parencite{R}, this document is unfit for serving as the basis of a verification effort; it is both a specification effort and a manual, written in plain English, with ambiguities and incomplete at times. Additionally, we found several mismatches between the text description and the behavior of the reference interpreter, GNU~R~\parencite{Rwebsite}.\footnote{For instance, according to the language definition, \mintinline{R}{if ("TRUE") 42} should raise an error, while the interpreter returns \mintinline{R}{42}.}
Crucially, the formal semantics should account for all the subtle cases of the R semantics, such as function call conventions described above, implicit type conversions, and so on.
This is necessary because these corner cases are indeed a typical place were bugs appear and are hard to track. 
A complete semantics for the full R language will inevitably be complex,
because of the large amount of such corner cases.

% This formalization is quite large, and we need to certify it.
This complexity in turn raises a meta-trust issue: 
how can a large semantics (and consequently the proofs made from it)
be trusted? Being able to relate a formalism to {\em trust sources} is a crucial aspect of the formalization process, and often requires a large amount of work to be done properly~\parencite{leroy2014pip}. This challenge has been faced repeatedly in attempts to provide formal foundations to JavaScript.
%
Some formalization approaches like $\lambda_{JS}$~\cite{Guha2010} and KJS~\cite{kjs} augment trust through extensive testing and comparison with existing implementations. JSCert~\parencite{popl14jscert} only uses testing, without directly comparing to an existing implementation, but further augments trust through the notion of a so-called {\em eyeball correspondence}, i.e.~a line-to-line syntactic connection, between the formalization (in Coq) and the ECMAScript specification (in English and pseudo-code).

\paragraph{Contributions.} 
We present \CoqR{}, a trustworthy formalization of the R programming language in the Coq proof assistant.
The formalization is a big-step operational semantics, in the form of an interpreter (Section~\ref{sec:coq:interp}). 

We say that this interpreter is {\em trustworthy} because we have followed two complementary techniques to maximize trust.
First, inspired by JSCert, the Coq interpreter has been written using a monadic encoding that allows for a direct {\em eyeball correspondence} with the C source code of GNU~R~\parencite{Rwebsite}. In the absence of a standardized formal semantics, GNU~R is the reference point that defines what  R really is.

Second, we have extensively {\em tested} the Coq interpreter against the GNU~R reference interpreter, using three test suites: the test suite of GNU~R itself (aprox. 3,600 loc), the test suite of the FastR implementation (aprox. 1,300 loc)~\parencite{kalibera2014fast}, and a custom test suite that we developed ourselves to exercise corner cases (aprox. 900 loc). 
%We note that these test suites have very little redundancy between themselves.
To this end, we have developed a testing framework that streamlines the process of running both the Coq interpreter and GNU~R on a set of test cases and report on mismatches and errors (Section~\ref{sec:testing:architecture}).

We also report on a proof effort to establish that memory invariants are preserved during execution, including some specific proof automation (Section~\ref{sec:proofs}). 
Finally, we report on the process of scaling up our interpreter in order to be able to import existing R libraries (Section~\ref{sec:library}), in particular the R base library (aprox. 19,000 loc).

Section~\ref{sec:related:work} discusses related work and Section~\ref{sec:conclusion} concludes.

% Given the size of our formalization,
% we consider this part to be the most important of our contributions.

% The development presented here, including the Coq interpreter, the testing framework, and the tests, is available online at:\\
% \url{https://github.com/Mbodin/proveR/releases/tag/DLS2018}\todo{make this tag exist on Github}.

% % Contributions.
% We introduce \CoqR{}

% a formalization of the R programming language in the Coq proof assistant.
% This is a continuation of a previous work~\parencite{CoqRCoqPL},
% \mb{Political choice here: is it a good idea to cite this previous work?}\et{no, skip - this wasn't a technical result, just a progress report/position paper}
% in which we formalised a small core of the R language.
% The additional contribution of this paper is the additional
% of a non-trivial quantity of R features,
% which enabled us to import R libraries.
%
%
% This two-factors method is very close to the one of JSCert,
% which we discuss in Section~\ref{sec:related:work}.



% % Outlines.
% \eti{update when paper is stable:}
% This paper is organized as follows.
% Section~\ref{sec:coq:interp} presents the Coq interpreter.
% In particular, Section~\ref{sec:eyeball:closeness} presents
% how this semantics is syntactically close to the C source code of R.
% Section~\ref{sec:testing:architecture} then presents our testing architecture.
% Not only this architecture is used as a way to relate our semantics
% with R reference interpreter,
% it also provided immediate benefits during the development of the semantics.
% Section~\ref{sec:driving:development} presents these benefits.
% The testing results are shown in Section~\ref{sec:test:results}.
% Finally, Section~\ref{sec:proofs} presents some proofs that have been done
% using our language formalization.

\section{Coq Interpreter}
\label{sec:coq:interp}

We develop the formal semantics of R in the form of an interpreter defined in Coq; therefore, this is a big-step operational semantics.
Operational semantics written as a Coq recursive function is usually not the best fit for Coq proofs---an inductive definition of the operational semantics is usually more convenient for reasoning---but our approach comes with a crucial advantage: it can be run, and thus tested.
%
In this section, we show how we define the Coq interpreter in order to achieve the first of the two mechanisms in place for trust, namely the eyeball correspondence with the GNU~R interpreter.

\subsection{Bridging the Gap between C and Coq}
\label{sec:monad}

The basic principle of the eyeball correspondence is that every one or two lines of the Coq interpreter should correspond to one or two lines of the C reference interpreter.

Of course, achieving a close correspondence between C and Coq versions of the same program is quite challenging, because C and Coq are widely different programming languages:
Coq is purely functional
whilst global side-effects are frequent in C.
Furthermore, Coq is designed to reject any function
whose behavior is not entirely defined
(it is for instance impossible to miss a case in a pattern-matching),
whilst C is known for its undefined behaviors.
Finally, contrary to C, Coq programs are required to terminate.

\begin{figure}[t]
\begin{minted}{Coq}
Inductive result (A : Type) :=
  | result_success : state -> A -> result A
  | result_error : state -> string -> result A
  | result_longjump : state -> context -> result A
  | result_impossible : state -> string -> result A
  | result_not_implemented : string -> result A
  | result_bottom : state -> result A.
\end{minted}
\caption{The result monad.}
\label{fig:result}
\end{figure}

In order to limit the impact that these differences can have on the eyeball correspondence, we introduce a {\em result monad}, which combines both the state, error, and fuel monads (Figure~\ref{fig:result}), and allows us to program in Coq ``as if it were C''.%
%
\footnote{Recall that monads allow purely functional programs to account for effectful computation, by means of implicit threading of information using a {\em binder}~\parencite{wadler:mscs1992}. For instance, the state monad threads a piece of state through a functional computation, accessible via monadic operations like \mintinline{Coq}{put} and \mintinline{Coq}{get}, thereby simulating a mutable store.}
More precisely, the result monad features the following constructors:\footnote{The result monad is similar to the one used in the JSExplain project~\parencite{JSExplain}, which aims at defining a JavaScript interpreter in Coq, readable by non-specialists. 
}
\begin{itemize}
\item The main constructor is \mintinline{Coq}{result_success}, used when a computation is successful.
In addition to the result (of type \mintinline{Coq}{A} in the definition),
it carries the global state (of type \mintinline{Coq}{state}). (We describe the representation of state later on in this section.)
%
\item The constructor \mintinline{Coq}{result_error} is meant to catch
errors thrown by GNU~R, for instance an R runtime typing error:
these errors are not catchable and immediately end the execution.
A \mintinline{Coq}{string} is provided to help the debugging process.
%
\item The constructor \mintinline{Coq}{result_longjump}
corresponds to a call to the \mintinline{C}{longjmp}
C function in GNU~R source code.
It only appears in constructs involving non-local jumps,
such as \mintinline{R}{break} or \mintinline{R}{return}.
The \mintinline{C}{longjmp} jumps to the corresponding
\mintinline{C}{setjmp} function,
which typically appears in loops and function calls.
For instance, Figure~\ref{fig:do_repeat:c} shows the C code
of the \mintinline{R}{repeat} feature of R,
which keeps on executing its argument.
Once a \mintinline{C}{longjmp} is executed
(for instance by a \mintinline{R}{break}),
the current program point is set to be Line~\ref{line:do_repeat:c:setjmp}.
The \mintinline{C}{setjmp} function then returns
the argument of the \mintinline{C}{longjmp}.
% This enables the interpreter to differenciate on the kind of non-local behavior.
We needed to add a special constructor
to translate this specific behavior of C.
%
\item Unspecified C behaviors
(such as dereferencing an invalid pointer)
are translated into
\mintinline{Coq}{result_impossible}.
Getting this result immediately ends the Coq interpreter:
it is meant to be unreachable.
Observing such a result would mean that a bug in GNU~R has been found, which could possibly be undetectable by running GNU~R due to a C compiler optimization.\footnote{At this date, we have not encountered this situation (yet?).}
% \et{has this happened? I guess not}
% \mbi{No it hasn't. What I meant is that in \CoqR{}, undefined behaviors always result in a special error,
%      whilst in GNU~R, this could result in a silent error due to compiler optimizations:
%      we are in theory able to catch ``bugs'' that direct testing on GNU~R wouldn't be able to catch.}
%
\item Given the size and complexity of the R language, it is important to be able to execute the Coq interpreter without it being fully complete.
The specific constructor \mintinline{Coq}{result_not_implemented} is thus important
for development; it is treated specifically in our testing framework, for instance to help identity which features one should focus on next.
%
\item Finally, \mintinline{Coq}{result_bottom} is returned
to end the execution when reaching the maximum number of executed instructions
(also called \emph{fuel}). This is meant to artificially make our interpreter terminate, despite the fact that the interpreted R program may not.
\end{itemize}

\begin{figure}
\begin{minted}[escapeinside=@@,linenos]{C}
SEXP do_repeat (EXP* call, EXP* op,
                EXP* args, EXP* rho){
  EXP* body;
  RCNTXT cntxt;
  checkArity (op, args);
  body = CAR (args);
  begincontext (&cntxt, CTXT_LOOP, rho, R_BaseEnv);
  if (setjmp (cntxt.cjmpbuf) != CTXT_BREAK) {@\label{line:do_repeat:c:setjmp}@
    for (;;) eval (body, rho);
  }
  endcontext (&cntxt);
  return R_NilValue;
}
\end{minted}
    \caption{C code of the \mintinline{C}{do_repeat} function}
    \label{fig:do_repeat:c}
\end{figure}

The result monad is associated with a monadic binder,
written \mintinline{Coq}{let%success}.
This binder expects its argument to evaluate to a result of the form
\mintinline{Coq}{result_success}. If so, it binds the carried result to a name, and transparently propagates the possibly-updated state.
All other kinds of results are transparently propagated to the top-level.
A similar monadic binder has been defined to handle
the special semantics of \mintinline{C}{setjmp}.
This obliviousness to global state, errors and non-termination is what enables a close correspondence between a program written in both languages.

% We believe that this helps to find bugs in \CoqR{}
% and to convey trust to the overall R semantics.

\subsection{Eyeball Correspondence}
\label{sec:eyeball:closeness}

\begin{figure*}[t]
    \centering{}
\begin{subfigure}{.54\textwidth}
\begin{minted}{C}
EXP* do_attr (EXP* call, EXP* op,
              EXP* args, EXP* env){
  EXP* argList, car, ans;
  /* ... */
  int nargs = R_length (args);
  argList = matchArgs (do_attr_formals, args, call);
  PROTECT (argList);
  if (nargs < 2 || nargs > 3)
    error ("Wrong argument count.");
  car = CAR (argList);
  /* ... */
  return ans;
}
\end{minted}
    \caption{original C function}
    \label{fig:c:do_attr}
\end{subfigure}
\begin{subfigure}{.45\textwidth}
\begin{minted}{Coq}
Definition do_attr globals runs S
    (call op args env : EXP_pointer) :=
  let%success nargs :=
    R_length globals runs S args using S in
  let%success argList :=
    matchArgs globals runs S
      do_attr_formals args call using S in
  if nargs <? 2 || nargs >? 3 then
    result_error S "Wrong argument count."
  else
    read%list car, _, _ := argList using S in
    (* ... *)
    result_success S ans.
\end{minted}
    \caption{Coq translation}
    \label{fig:coq:do_attr}
\end{subfigure}
    \caption{Original C function and Coq translation of \mintinline{C}{do_attr}}
    \label{fig:do_attr}
\end{figure*}


% % Definition of the line-to-line correspondence.
% One key specificity of this interpreter is that it has been designed
% to be similar to the original C source code of GNU~R.
% More precisely, they are related by a line-to-line correspondence
% (also called \emph{eyeball closeness})\et{is closeness a standard term here? (eyeball correspondence sounds better to me)}:
% every one or two lines of our interpreter
% correspond to one or two lines of the reference interpreter.
% %

By developing \CoqR{} as a monadic interpreter using the result monad introduced above, we are able to achieve an eyeball correspondence between the C and Coq interpreters. This correspondence is extremely helpful during development:
whenever a bug is encountered while testing, we localize the function responsible for the bug and then check the line-to-line correspondence.
Such checks are quick and easy to perform, often leading to a quick fix of \CoqR{}.
%

Figure~\ref{fig:do_attr} shows an example of the eyeball correspondence that can be achieved using the result monad. Figure~\ref{fig:c:do_attr} shows a C function, and Figure~\ref{fig:coq:do_attr} its Coq translation.
The binder \mintinline{Coq}{let%success} is used when calling a function. 
Thanks to the monadic encoding, the calls to \mintinline{Coq}{R_length}
and \mintinline{Coq}{matchArgs} may return an unsuccessful result, but the code does not need to be explicit about that possibility; the code after a call is only executed if the result denotes success. Similarly, the \mintinline{C}{return} statement from C is translated to \mintinline{Coq}{result_success}, and raising an error is performed using \mintinline{Coq}{result_error}. 

The other differences that can be observed are several arguments systematically passed to each function (\mintinline{Coq}{globals}, \mintinline{Coq}{runs}, and \mintinline{Coq}{S}), as well as the use of 
\mintinline{Coq}{read%list} 
instead of \mintinline{C}{CAR} in the C version, and the fact that the use of the \mintinline{C}{PROTECT} macro is missing from the Coq version. We clarify each of these points in the following subsections.

% The \mintinline{Coq}{S} argument and the use 
% are related to the modeling of the heap, discussed in Section~\ref{sec:coq:structure}.

% The \mintinline{Coq}{globals} argument is discussed in Section~\ref{sec:coq:structure}.

% The \mintinline{Coq}{runs} argument is related to dealing with non-termination, and is discussed in Section~\ref{sec:fuel}.



\subsection{Modeling the Heap}
\label{sec:heap}

\begin{figure}
    \centering{}
    \begin{tikzpicture}
        \node [draw = black, rectangle, minimum height = 6mm, anchor = base] (hlist) {header} ;
        \node [draw = black, rectangle, minimum height = 6mm, anchor = base, right = 0pt of hlist] (car) {car} ;
        \node [draw = black, rectangle, minimum height = 6mm, anchor = base, right = 0pt of car] (cdr) {cdr} ;
        \node [draw = black, rectangle, minimum height = 6mm, anchor = base, right = 0pt of cdr] (tag) {tag} ;
        \node [left = 2mm of hlist] (nlist) {List:} ;

        \node [draw = black, rectangle, minimum height = 6mm, anchor = base, below = 2mm of hlist] (hvector1) {header} ;
        \node [draw = black, rectangle, minimum height = 6mm, anchor = base, right = 0pt of hvector1] (size1) {size} ;
        \node [draw = black, rectangle, minimum height = 6mm, anchor = base, right = 0pt of size1] (i1) {\(i_1\)} ;
        \node [draw = black, rectangle, minimum height = 6mm, anchor = base, right = 0pt of i1] (i2) {\(i_2\)} ;
        \node [anchor = base, right = 0pt of i2] (i3) {\(\ldots\)} ;
        \node [draw = black, rectangle, minimum height = 6mm, anchor = base, right = 0pt of i3] (in) {\(i_n\)} ;
        \node [left = 2mm of hvector1] (nvector1) {Integer vector:} ;

        \node [draw = black, rectangle, minimum height = 6mm, anchor = base, below = 2mm of hvector1] (hvector2) {header} ;
        \node [draw = black, rectangle, minimum height = 6mm, anchor = base, right = 0pt of hvector2] (size2) {size} ;
        \node [draw = black, rectangle, minimum height = 6mm, minimum width = 1cm, anchor = base, right = 0pt of size2] (c1) {\(c_1\)} ;
        \node [draw = black, rectangle, minimum height = 6mm, minimum width = 1cm, anchor = base, right = 0pt of c1] (c2) {\(c_2\)} ;
        \node [anchor = base, right = 0pt of c2] (c3) {\(\ldots\)} ;
        \node [draw = black, rectangle, minimum height = 6mm, minimum width = 1cm, anchor = base, right = 0pt of c3] (cn) {\(c_n\)} ;
        \node [left = 2mm of hvector2] (nvector2) {Complex vector:} ;
    \end{tikzpicture}
    \caption{Basic language elements in memory}
    \label{fig:basic:language:elements}
\end{figure}

% Basic language elements.
We now describe how we modeled GNU~R's heap.
Although the underlying language is C,
GNU~R has been designed with a specific structure in mind~\parencite{R}.
Almost all objects manipulated by the interpreter
are called \emph{basic language elements},
or \mintinline{C}{EXP} in C.
Each of them are composed of a header and some data.
%
The header stores the type of the basic language element,
a list of attributes,
as well as several mostly-boolean informations
(for instance whether it can be safely updated in place).
There are \(24\) different types of basic language elements in R,
\(9\) of which being different kinds of vectors.
%
The stored data depends on the type of the element.
For instance, lists contain three pointers:
one to the first element (named \mintinline{Coq}{car}),
to the queue of the list (\mintinline{Coq}{cdr}),
and to an optional name for the first element (\mintinline{Coq}{tag}).
Vectors store their length,
followed by a C array in memory.
The size of this array depends both of its length
and the type of vector.
Figure~\ref{fig:basic:language:elements} illustrates this
with integer and complex vectors
(complexes are composed of two floats).
%
The way memory is used in C
makes it easy to unguardedly access a cell out of bounds,
which would lead to an undefined behavior.



% Guarded accesses in Coq to represent unguarded accesses in C.
This is an issue,
as we cannot directly translate unguarded C accesses into Coq:
we need a model of the heap.
Figure~\ref{fig:EXP} shows how we defined \mintinline{Coq}{EXP} in Coq.
Basic language elements are records storing a header
and data,
which in turn is defined as a sum type.
For instance, lists are defined by three pointers.
Vectors are records storing their length and a list:
in Coq, the data of vector is stored directly in the \mintinline{Coq}{EXP} structure
and not following it in memory as in C.

\begin{figure}
\begin{minted}{Coq}
Record ListStruct := make_ListStruct {
    list_carval : EXP_pointer ;
    list_cdrval : EXP_pointer ;
    list_tagval : EXP_pointer
  }.

Record Vector_EXP (A : Type) := make_Vector_EXP {
    Vector_length : nat ;
    Vector_data :> list A
  }.

Inductive EXPData :=
  | listExp : ListStruct -> EXPData
  | envExp : EnvStruct -> EXPData
  | EXP_VectorInteger : Vector_EXP int -> EXPData
  | EXP_VectorComplex : Vector_EXP complex -> EXPData
  (* ... *).
Coercion listExp : ListStruct >-> EXPData.
Coercion envExp : EnvStruct >-> EXPData.
(* ... *)

Record EXP := make_EXP {
    EXP_header :> EXPHeader ;
    EXP_data :> EXPdata
  }.
\end{minted}
    \caption{Basic language elements (\mintinline{C}{EXP}) in Coq}
    \label{fig:EXP}
\end{figure}

% About the use of coercions.
To ease readability, coercions have been used extensively.
Coercion is a mechanism to mark some constructors as implicit.
For instance, if Coq expects a \mintinline{Coq}{EXPData}
and is given a \mintinline{Coq}{ListStruct},
then the constructor \mintinline{Coq}{listExp} will be implicitly called
thanks to the corresponding line in Figure~\ref{fig:EXP}.
In the context of \CoqR{},
this is more than a simple syntactic notation
as it helps the line-to-line correspondence
by hiding what is not present in C:
if one points to either a list or an environment,
the C notation to access its list or its environment is the same.
%
Of course, this implicit notation is only one-way:
given a \mintinline{Coq}{ListStruct},
we can convert it into an \mintinline{Coq}{EXPData},
but to perform the converse, we have to pattern-match
on the shape of the \mintinline{Coq}{EXPData}.
%
This pattern-matching is performed by specific monadic binders.
For instance in Figure~\ref{fig:coq:do_attr}, \mintinline{Coq}{read%list}
gets the \mintinline{Coq}{EXP} stored in the state \mintinline{Coq}{S}
and pointed by \mintinline{Coq}{argList},
then pattern-matches it as a list,
extracting the \mintinline{Coq}{car}, \mintinline{Coq}{cdr},
and \mintinline{Coq}{tag} fields.
If the pointer is not in the domain of the state \mintinline{Coq}{S}
or if the associated \mintinline{Coq}{EXP} object is not a list,
then \mintinline{Coq}{result_impossible} is returned:
this corresponds to an undefined behavior in C
(dereferencing an invalid pointer or accessing the wrong projection of a \mintinline{C}{union}).
The accesses in Coq are thus guarded by monadic binders,
whilst closely mimicking the unguarded accesses of C.


% Not modeling this part enabled us to focus on the computational part.
%
%
% At this stage, the reader should be able
% to compare the C and Coq programs of Figure~\ref{fig:do_attr}
% line by line.
% The rest of \CoqR{} was similarly defined.

\subsection{Dealing with Global Variables}
\label{sec:globals}

% Initialization of R and global variables.
The GNU~R interpreter features over \(80\) global variables that need initialization, and are subsequently unchanged. 
The initialization of these internal variables
actually represents a large portion of the source code.
Even before importing any libraries, a lot of basic language elements
are created and stored in global variables.

For instance, the often-used variable \mintinline{C}{R_NilValue}
is set to be a list whose \mintinline{C}{car}, \mintinline{C}{cdr},
and \mintinline{C}{tag} fields point to \mintinline{C}{R_NilValue} itself.
This element is used instead of the \mintinline{C}{NULL} pointer
to mark any non-present element. Another important global variable is 
\mintinline{C}{R_FunTab}, which is the {\em symbol table} that maps operation and function names to C functions implementing them. (We exploit this structuring of the interpreter for building \CoqR{} in an incremental manner---see Section~\ref{sec:coq:structure}.)

%
The initialization of global variable is fairly subtle. Most initializations perform local computations, calling core functions.
To avoid this circular dependency---which Coq would not accept---one could parametrize each core function by the value of the global variables it uses.
This would however not scale, considering the size of the project and the number of global variables involved.
%
Instead, we parameterize each function of \CoqR{} by a single \mintinline{Coq}{globals} environment, which is a mapping from a definite set of global variables to \mintinline{Coq}{EXP_pointer}. This additional argument can be seen in the Coq code of Figure~\ref{fig:coq:do_attr}: it is passed along at each call site.

To make definitions more convenient, we use coercions to make Coq implicitly perform a lookup in the \mintinline{Coq}{globals} environment whenever a global variable is read. Therefore, accessing global variables is transparent, as illustrated by the use of \mintinline{C}{do_attr_formals} in Figure~\ref{fig:coq:do_attr}.


\begin{figure*}
    \centering{}
\begin{subfigure}{.5\textwidth}
\begin{minted}{C}
  static EXP* do_attr_formals = NULL;
  if (do_attr_formals == NULL)
    do_attr_formals =
      allocFormalsList2 (install ("x"),
                         install ("which"));
\end{minted}
    \caption{C snippet}
    \label{fig:c:do_attr:formals}
\end{subfigure}
\begin{subfigure}{.49\textwidth}
\begin{minted}{Coq}
Definition do_attr_init globals runs S :=
  let%success x :=
    install globals runs S "x" using S in
  let%success which :=
    install globals runs S "which" using S in
  allocFormalsList2 globals S x which.
\end{minted}
    \caption{Coq translation}
    \label{fig:coq:do_attr:formals}
\end{subfigure}
    \caption{Another snippet of \mintinline{C}{do_attr} and its Coq translation}
    \label{fig:do_attr:formals}
\end{figure*}

% Static global variables.
\paragraph{Hidden global variables.} In fact \mintinline{C}{do_attr_formals} is a {\em hidden} global variable, introduced locally with the C \mintinline{C}{static} keyword inside the \mintinline{C}{do_attr} function. Such a variable is persistent across calls, just like a standard global variable.

In place of the first commented-out part in Figure~\ref{fig:c:do_attr}, the code actually defines the \mintinline{C}{static} variable \mintinline{C}{do_attr_formals}, as shown in Figure~\ref{fig:c:do_attr:formals}. Upon the first call of \mintinline{C}{do_attr}, the variable \mintinline{C}{do_attr_formals} is initialized by a basic language element. The value is kept across calls in order to avoid a costly reallocate at each call.
%
Observe that this pattern exactly follows the scheme of the other global variables: the variable is initialized once, and then never changes. Consequently, we treat such a \mintinline{C}{static} variable just like a global variable. We extracted out the part of \mintinline{C}{do_attr} that performs initialization, shown in Figure~\ref{fig:coq:do_attr:formals}.
This code is executed after the standard global variables are initialized.
% \et{what if the initialization of a static var uses some argument of the first call? does it ever happen?}\mb{I've never seen it. In such a case, I just add these variables in the state (this already happenned, but is rare).}


\subsection{Dealing with Non-Termination}
\label{sec:fuel}
% Structuring the fuel.
Another additional argument present in Figure~\ref{fig:coq:do_attr}
is the \mintinline{Coq}{runs} argument.
This argument aims at factorizing the fuel given to Coq functions
to make them artificially terminate.
The usual way to do this is to make each function check whether its fuel
reached \(0\), and if so return \mintinline{Coq}{result_bottom}.
It is however cumbersome to do that manually, and affects the line-to-line correspondence, since such a check does not exist in C.
%
We solve this issue by following the same method as in JSCert:
instead of a fuel argument, each function takes a record \mintinline{Coq}{runs}.
This record stores all recursive functions as its projections.
Each recursive call in C is then translated by calling
the corresponding projection of the record,
as in a regular fix-point combinator.\et{can you give an example of such a translation?}
% \mb{I guess that this paragraph could be improved a lot\ldots}
Once all functions have been defined,
one can then define a function \mintinline{Coq}{runs} taking some fuel:
at each step, its projections are functions taking a \mintinline{Coq}{runs}
with less fuel as argument;
when reaching \(0\), all its projections systematically return \mintinline{Coq}{result_bottom}.
Figure~\ref{fig:runs} shows its Coq definition.
%
% \mb{Maybe we just don't want to speak about this:}
% \mbi{
% Note that the symbol table has to be one of the projections of \mintinline{Coq}{runs},
% otherwise a strangely-written function could in theory fetches itself from the symbol table
% and executes it, leading to an unwanted loop.
% }
% %
In addition to passing the extra-argument argument, this idiom only requires one pattern-matching on fuel in the whole \CoqR{} interpreter; it is thus a very lightweight way to introduce termination. 

\begin{figure}
\begin{minted}{Coq}
Fixpoint runs max_step globals :=
  match max_step with
  | O => {|
      runs_while_loop := fun _ S _ _ _ =>
        result_bottom S ;
      runs_eval := fun S _ _ =>
        result_bottom S ;
      (* ... *) |}
  | S n => {|
      runs_while_loop := fun A S (a : A) expr stat =>
        while_loop globals (runs n) A S a expr stat ;
      runs_eval := fun S e rho =>
        eval globals (runs n) S e rho ;
      (* ... *) |}
  end.
\end{minted}
    \caption{Definition of \mintinline{Coq}{runs} in Coq}
    \label{fig:runs}
\end{figure}


\subsection{Limitations}
% About garbage collection.
The use of the \mintinline{C}{PROTECT} macro in Figure~\ref{fig:c:do_attr} is missing in the Coq translation. This macro use performs a garbage collecting action, namely it saves the object \mintinline{C}{argList} from garbage collection.
At this stage, we chose not to model the garbage collection aspect of GNU~R in \CoqR{}. Indeed, garbage collection adds complexity to the interpreter, but is not supposed to affect the result of any computation. For now, we focus on the computational part of GNU~R.

% Ignored aspects.
% As stated in Section~\ref{sec:eyeball:closeness},
% we chose to ignore some aspects of the source code of GNU~R.
% All garbage collection commands have been formalized out.
Additionally, \CoqR{} only considers ASCII strings, and hence does not support various locales and character encodings supported by R. 
More generally, \CoqR{} ignores any possibility to dynamically
parametrize the behavior of the interpreter using options
stored the shell environment.

% \mb{Are there other things we should mention?}

Note that the eyeball correspondence between GNU~R and \CoqR{} would pay off in the future if one wants to extend \CoqR{} to account for some of these features, such as garbage collection.



\subsection{Incremental Development of \CoqR{}}
\label{sec:coq:structure}

R is by no means a small language.
As a result, the \CoqR{} project spans over 18,000 lines of Coq definitions.
This is larger than in the JSCert project~\parencite{popl14jscert}, which consists of 12,500 lines of Coq definitions.
% \et{ref + how large is JSCert?}\mb{We already quote it several times in the paper: isn't it too much?}
% \mbi{For the statistics: \CoqR{} is 18,000 lines of Coq definitions + 1500 lines of Coq proofs.
%     JSCert is 12,500 lines of Coq definitions + 5,000 lines of Coq proofs. Both according to \texttt{coqwc}.
%     It is difficult to compare these figures, but I find the comparizon with JSCert impressive.}
Therefore, for pragmatical reasons, it is important to be able to proceed {\em incrementally} in the development of \CoqR{}. We hence identify a minimal core of R to support initially, and then incrementally extend \CoqR{}. To this end, we exploit the fact that GNU~R is structured around a huge {\em symbol table} that contains all functions present in the initial environment of R, whose code is written natively in C.

\begin{figure}
\begin{minted}{C}
FUNTAB R_FunTab[] = {
  {"if",        do_if,       2,  true,  false},
  {"while",     do_while,    2,  true,  false},
  {"break",     do_break,    0,  true,  false},
  {"return",    do_return,   1,  true,  false},
  {"function",  do_function, -1, true,  false},
  {"<-",        do_set,      2,  true,  false},
  {"(",         do_paren,    1,  true,  true},
  {".Internal", do_internal, 1,  true,  false},
  {"which",     do_which,    1,  false, true},
  {"+",         do_arith1,   2,  true,  true},
  {"-",         do_arith2,   2,  true,  true},
  {"cos",       do_math20,   1,  true,  true},
  {"sin",       do_math21,   1,  true,  true},
  /* ... */ }
\end{minted}
    \caption{Symbol table of GNU~R}
    \label{fig:names}
\end{figure}

Figure~\ref{fig:names} shows an excerpt of the symbol table. 
This C array associates the name of each function with the corresponding C function implementing it, along with its arity and some additional information.\footnote{Namely, whether the function is to be directly defined in the initial environment or available in the \mintinline{R}{.Internal} construct, and whether it evaluates lazily or eagerly.}
The symbol table contains more than 700 entries.
% \et{how much of the 700 entries of the symbol table do we currently support?}
% \mb{112 out of 722. Some of these functions are only partially implemented, but most of the 112 are completely translated.}
Interestingly, all syntactic constructs correspond to a C function. This includes constructs like \mintinline{R}{if}, \mintinline{R}{while}, \mintinline{R}{return}, and even assignments: although the parser accepts a seemingly imperative syntax, it is internally replaced by Lisp-style function calls!
For instance, the two abstract syntax trees generated
by GNU~R parser for the two lines below are identical.\footnote{
    R usually uses a lazy evaluation strategy:
    the expression \mintinline{R}{x <- 1} is only evaluated
    when actually used.
    Performing side effects in function arguments can yield to unexpected results,
    but is acceptable for an \mintinline{R}{if}.
}
\begin{minted}{R}
if (TRUE) x <- 1 else return ()
"if" (TRUE, "<-" (x, 1), "return" ())
\end{minted}

The symbol table provides us with an opportunity for incremental development, because this array clearly defines a set of functions that can be individually removed from GNU~R without breaking the overall interpreter---only the parts using them. We therefore consider the {\em core} of the R language to consist of the functions used to evaluate R expressions that are \emph{not} present in the symbol table. Core functions include the execution process for function calls, environments, closures, promises (delayed evaluation),
as well as the parts initializing the symbol table. Constructs like \mintinline{R}{if} and \mintinline{R}{while} are not part of the core,
but some assignment functions are, because they are used when calling functions.

All functions in the symbol table are then considered {\em additional features}. The first version of the interpreter only supported the core of R, allowing us to focus the effort on a very restricted sub-language.
We were then able to add additional features one at a time, by implementing
the associated function and adding it to the symbol table. 
In the current \CoqR{} development, out of the 18,000 lines, around 5,000 lines are for the core of R,  and 4,000 lines are for additional features.
\et{what about the other 9000 lines?}
At the time of writing, we support 112 entries from the symbol table, which is enough to run the entire base library of R (Section~\ref{sec:library}).

% \eti{I'm here (haven't gone through all text of section 2 above yet, but haven't looked at parsing at all)}

\subsection{Parsing R}
\label{sec:shim}

Verified software, e.g. written in Coq, needs to interact with less trusted code, for instance for performing input/output. This additional code is called the \emph{shim}, and unfortunately, it usually concentrates most bugs in certified software~\parencite{Yang:2011:FUB:1993498.1993532}. 
% Why the shim is important.
% Bugs can still appear in verified softwares.
% Indeed, such softwares are not entirely formalized in Coq:
% some additional code is added to perform the program's inputs and outputs.
In the case of \CoqR{}, a particularly important part of the shim is the R parser. Parsing real-world programming languages is known to be challenging, so in order to maximize trust, we first tried to develop the parser in Coq
using the Menhir tool~\parencite{jourdan2012validating} in order to obtain a formally-verified parser. Unfortunately, the grammar of GNU~R (defined in Bison) does not respect the grammar constraints of Menhir's Coq front-end. We thus had to fall back on Menhir's OCaml front-end, making the parser part of the shim.

In order to achieve high confidence in the parser implementation, we nevertheless can follow the eyeball correspondence methodology. 
% Parsing in the shim.
Consequently, we did not optimize or change GNU~R's grammar in any way. While doing so might have enabled us to use the Coq front-end of Menhir, it would have resulted in a very different grammar from GNU~R's, and spotting bugs and inconsistencies between both grammars would have been challenging.

Sticking to the original grammar has its own downside, though. First, the Bison grammar of GNU~R is ambiguous, with 27 shift/reduce conflicts.
% These conflicts typically appear in expressions such as
% \mintinline{R}{repeat 4 * break},
% which could be read as \mintinline{R}{(repeat 4) * break}
% (which would loop)
% or \mintinline{R}{repeat (4 * break)}
% (which would terminate immediately),
% depending on the interpretation.
% \mbi{I'm not confident about this example.
%     This is the example given by Menhir using the \texttt{explain} option,
%     but I believe that the real issue is somewhere else.
%     Is it an issue if we don't provide an example for this paragraph?}
As a consequence, both Bison and Menhir make some arbitrary choices,
which could in theory be different (we checked through testing that they do not).
% both choosing the second option above in practice.
% Side effects in the grammar
Another source of potential mismatch
between the parsers of GNU~R \CoqR{} are new lines.
There are contexts in R where new lines are significant
and others where they are not.
For instance, in \mintinline{R}{{ function () break + 1 }},
adding a new line after the \mintinline{R}{function} or \mintinline{R}{+} keywords does not change the final result,
but adding a new line after the \mintinline{R}{break} keyword does.
%
In such situations, lexers usually produce the new line token
nevertheless, leaving to the parser the choice to ignore it or not.
However, in GNU~R, the lexer reads a global boolean variable %\mintinline{C}{eatLines}
whenever it encounters a new line, which indicates whether the lexer should ignore the new line.
This variable is controlled by the parser:
the lexer and the parser thus communicate through side-effects.
%
Such effects are usually considered to be bad practice
as they heavily depend on when the parser calls the lexer
(and they might become get desynchronized).
%
To keep the line-to-line correspondence,
we nevertheless built the same communication channel
between the lexer and the parser in OCaml.
Unfortunately, Bison and Menhir do not always call the lexer
the same way.
%
For instance, empty blocks \mintinline{R}{{}} wrongly
lead new lines to be eaten in our parser.
This is easily fixable by replacing them
by the equivalent R constant \mintinline{R}{NULL}.

Despite the few differences of behavior,
we believe that our methodology helped us
reduce the amount of bugs in the parser.
The differences of behavior are precisely known
and easily fixable in the parsed R code.
%
%


\section{Formal Reasoning about R}
\label{sec:proofs}

In this section, we answer one of the objective stated in the introduction:
our operational semantics should be usable to build proofs about the R language. This section describes one use case:
proving that invariants about the state of the memory are preserved during execution. We also discuss the associated need for proof automation.

As described in Section~\ref{sec:heap},
each basic language element in R is associated one of 24 types,
and each of these types are differently stored in memory.
Figure~\ref{fig:invariants:definition} shows a snippet
of our invariants defined by the \mintinline{Coq}{safe_SExp} inductive property.
%
The constructor \mintinline{Coq}{safe_ListStruct} captures the requirements on well-formed lists. The requirements are expressed using the predicate \mintinline{Coq}{may_have_types S l p}, which 
states that the pointer \mintinline{Coq}{p}
is associated in the state \mintinline{Coq}{S} with an object
whose type is in the list \mintinline{Coq}{l}. Hence, the hypothesis on \mintinline{Coq}{cdr} states that the tail of a list is either a list
(\mintinline{Coq}{ListSxp}) or nil (\mintinline{Coq}{NilSxp}).\footnote{The type \mintinline{Coq}{NilSxp} is the type of the \mintinline{Coq}{R_NilValue} global variable (see Section~\ref{sec:globals}); it is used both to end lists and to indicate a missing information.}
Similarly, the constructor states that the tag
of a list is either a character vector or a \mintinline{Coq}{NilSxp} element.
Note that no constraint is specified for the first element \mintinline{Coq}{car} of the list: lists in R are heterogeneous.
%
As another example, the constructor \mintinline{Coq}{safe_StrStruct} states that a string vector contains an array of C pointers,
all of which should be associated with a character vector in memory.

\begin{figure}
\begin{minted}{Coq}
Inductive safe_SExp S : SExp -> Prop :=
  | safe_ListStruct : forall car cdr tag,
    may_have_types S [NilSxp ; ListSxp] cdr ->
    may_have_types S [NilSxp ; CharSxp] tag ->
    safe_SExp S (make_ListStruct car cdr tag)
  | safe_StrStruct : forall data,
    (forall a, Mem a data ->
      may_have_types S [CharSxp] a) ->
    safe_SExp S (make_StrStruct data)
  (* ... *).
\end{minted}
    \caption{Typing invariants for memory during R execution}
    \label{fig:invariants:definition}
\end{figure}


\begin{figure}
\begin{minted}{Coq}
Lemma do_attr_result :
  forall S globals call op args env,
  safe_state S ->
  safe_globals S globals ->
  safe_pointer S args ->
  may_have_types S [NilSxp; ListSxp] args ->
  (* ... *)
  result_prop (fun S' ans =>
      safe_state S' /\ safe_globals S' globals
      /\ safe_pointer S' ans)
    (do_attr globals runs S call op args env).
Proof.
  introv OKS OKglobals OKargs Targs. unfolds do_attr.
  cutR R_length_result. computeR.
  cutR matchArgs_result. computeR.
  (* ... *)
Qed.
\end{minted}
    \caption{Example of tactic usage}
    \label{fig:do_attr_result}
\end{figure}

Such invariants are relatively simple, but given the size of the formalization,
they are quite long to establish. Proving that some step of the interpreter preserves the invariants quickly becomes very tedious. In order to address this, we developed various Coq tactics to ease the proof process.
These tactics are mainly useful to propagate known information
through state changes.
 % such operations would have been long and cumbersome for the user, and it automates relatively easily.

Figure~\ref{fig:do_attr_result} illustrates the use of these tactics, with a lemma that states that the \mintinline{Coq}{do_attr} function
defined in Figure~\ref{fig:coq:do_attr} produces a result
that satisfies the invariants.
%
The \mintinline{Coq}{safe_state} predicate specifies
that the given state only stores objects that satisfy the invariants, and similarly 
for the global variables of \mintinline{Coq}{globals} with the predicate \mintinline{Coq}{safe_globals}.
The arguments \mintinline{Coq}{call}, \mintinline{Coq}{op},
\mintinline{Coq}{args}, and \mintinline{Coq}{env} of \mintinline{Coq}{do_attr}
are also assumed to satisfy these invariants,
in addition to being of the expected type.
%
In the conclusion of the lemma, the \mintinline{Coq}{result_prop} predicate enables us
to specify what the resulting state of \mintinline{Coq}{do_attr} should satisfy,
whilst ignoring non-interesting cases
such as \mintinline{Coq}{result_not_implemented} or \mintinline{Coq}{result_bottom}.
Indeed, reaching one of these results means that the result is out of scope for the  interpreter.
\et{will turn into a forward ref if we move proof section earlier} 
This is the reason why these are not considered harmful
during the testing process (see Section~\ref{sec:test:methodology}).
In the normal result, we state that the invariants are still satisfied.

The proof closely follows the source code of \mintinline{Coq}{do_attr}.
After introducing the hypotheses, the function \mintinline{Coq}{do_attr} is unfolded,
leaving its definition ready to be processed by further tactics.
In Figure~\ref{fig:coq:do_attr}, we can see that \mintinline{Coq}{do_attr}
starts by calling \mintinline{Coq}{R_length}.
In the proof we use the \mintinline{Coq}{cutR} tactic with a lemma about \mintinline{Coq}{R_length}. This novel tactic discharges the premises of the lemma and introduces the resulting state:
only the success case is left, the other kinds of results being transparently propagated.
% As for \mintinline{Coq}{do_attr}, the error case yields \mintinline{Coq}{False}
% and is discharged by the tactic.
The call to \mintinline{Coq}{R_length} is thus rewritten
to a simple expression of the form 
\mintinline{Coq}{result_success S' n},
where \mintinline{Coq}{n} is the number returned by \mintinline{Coq}{R_length}.
%
We then apply the \mintinline{Coq}{computeR} tactic.
This is the most important tactic provided by our framework:
it moves forwards in the current expression,
propagating everything that can be propagated.
In the example, it unfolds the \mintinline{Coq}{let%success} monadic binder,
as this binder is now associated by a fully-computed result
---thanks to the \mintinline{Coq}{cutR} tactic.
It also updates all properties known to hold for the previous state \mintinline{Coq}{S}
to the new state \mintinline{Coq}{S'} using the results
of the \mintinline{Coq}{R_length_result} lemma.
For instance, the hypothesis \mintinline{Coq}{safe_pointer S args}
is replaced by \mintinline{Coq}{safe_pointer S' args}.
This transition is not particularly difficult to prove
given the right lemmae, but it can be extremely cumbersome to manually perform this transition for each and every available hypotheses.
%
The proof continues by applying the tactic \mintinline{Coq}{cutR} again
with a lemma about \mintinline{Coq}{matchArgs},
then \mintinline{Coq}{computeR} to propagate the hypotheses. And so on.

We have proven that the invariants are safely propagated throughout the execution of some chosen functions. The proof for the whole formalization is still work in progress. Given the size of the formalization,
we consider that proving such simple typing invariants
was already too big to be entirely manually proven:
automation was necessary to ease the proving process
and deal with such sizes.
%
We also found that building the \mintinline{Coq}{cutR}
and \mintinline{Coq}{computeR} in Ltac---%
the tactic language of Coq---%
was relatively straightforward.
As a consequence, we do not expect major difficulties
to adapt or build similar tactics for other kinds of proofs.

\et{end with a perspective on program logics}


\section{Testing Architecture}
\label{sec:testing:architecture}

Being able to syntactically relate our interpreter
with the source code of GNU~R helped us catch numerous bugs---%
in some sense as a variant of Linus's law.
However, given the small number of people
involved in the \CoqR{} project compared to the size of the produced interpreter,
some bugs may be left unnoticed.
% A relevant commit: https://github.com/Mbodin/proveR/commit/03708d1bc5f5ab6af5fd5668845472ffc9d9a6fb
To be really able to state that the \CoqR{} interpreter is trustable,
we need to test it.
%
We developed a testing framework with two different goals.
First, being able to certify the absence of bugs in our interpreter:
no bug should be left unnoticed by the testing framework.
Second, helping our development by providing useful reports.
In particular, as few safe results as possible should be marked as bugs.

\subsection{Methodology}
\label{sec:test:methodology}

\todo{}

Various kinds of tests (multiline, line-by-line, tests that are expected to fail, etc.).

What is considered to be a failure.

We believe that this scheme can be reused in other projects.

\subsection{Driving the Development Process}
\label{sec:driving:development}

\begin{figure}
    \includegraphics[width=.5\textwidth]{framework.png}
    \caption{Graphical interface of the testing framework}
    \label{fig:testing:interface}
\end{figure}

\todo{}

Identifying low-hanging fruits.

How the other results (Potential fail, Not implemented) helped the Coq development.

\subsection{Results}
\label{sec:test:results}

\todo{}

Bisect results.

Bugs found (and where).

How much tests are passed and failed.
What does this mean (one line can trigger more than one pass).

GNU~R test stuites (3,600 lines), FastR (1,300 lines), and ours (900 lines).

We extended the testing framework during development by adding new kinds of recognised
data structure.
We consider that the amount of work to extend the framework in another direction
(thus reducing the number of Unknown) is sufficiently low.


\section{Base Library}
\label{sec:library}

\subsection{Description}
\label{sec:library:description}

% The need to execute the base library.
Prior to execute any expression, GNU~R performs a lot of actions.
First, the heap is initialised.
This process involves initialising most global variables.
Then, GNU~R executes the base library.
It is a group of files written in R,
totalizing 19,000 lines of code.
%
This means that we have to be able to run the base library
to correctly test our interpreter.
For instance, without the base library,
no variable named \mintinline{R}{T} is defined:
running the program \mintinline{R}{T} results in a lookup error
in our interpreter whilst resulting in \mintinline{R}{TRUE} in R.
After running the base library,
which includes a line of the form \mintinline{R}{T <- TRUE},
our interpreter behaves as R on this same program.

% Example of typical function definition in the base library.
Most of these functions are just links to internal functions
with some argument checking or default argument.
Below is an example:
the defined function \mintinline{R}{which} behaves very similarly
to the internal \mintinline{R}{which} function.
The difference is that \mintinline{R}{which} takes two additional
optional parameters.
With their default values, the behavior of this function
is the same as the corresponding internal function:
this definition extends the original simpler behavior of the function.
\begin{minted}{R}
which <- function (x, arr = FALSE, names = TRUE) {
    wh <- .Internal (which (x))
    if (arr && !is.null (d <- dim (x)))
        array (wh, d, dimnames (x), names = names)
    else wh
}
\end{minted}

% About the not-implemented results.
These definitions are easily run:
only the \mintinline{R}{function} keyword is necessary
to define the function \mintinline{R}{which}.
However, once the base library has been executed,
a not-implemented exception will be thrown
if one actually calls the function \mintinline{R}{which}.
Indeed,
the internal function \mintinline{R}{.Internal (which (x))}
has not yet been implemented.
%
% This behavior is expected.
It may seem pointless to execute a function definition
that our interpreter can not execute without failing.
The reason is that failing because of non-implemented features
is harmless:
we know that this result can be safely ignored,
and our testing framework reports it as such.
On the other hand,
if we would not have executed the base library,
then the interpreter might fail with an error---%
stating for instance that the \mintinline{R}{which} function
does not exist---%
whilst GNU~R runs successfully.
Such a difference of behavior would be reported
as a bug by our testing framework,
whilst a not-implemented exception would not.
Being able to run the base library thus ensures
that the testing framework correctly classifies
the results of \CoqR{}.

% Computational content in the base library.
The base library also prepares the base environment.
For instance, the file \texttt{constants.R} of the base library
contains the definition below.
Such definitions are more complex as they involve computations:
to be able to run the base library,
we need to implement the \mintinline{R}{atan} function---%
in this case, using an OCaml hook.
Other features that had to be implemented
to run the base library
include functions to create new environments,
logical operators,
the \mintinline{R}{substitute} function,
the \mintinline{R}{$} operator \ignore$% Added to help my TeX syntax highlighting…
(which fetches an identifier in a named list or an environments),
as well as various internal functions.
\begin{minted}{R}
pi <- 4 * atan (1)
\end{minted}

% Result.
We have been able to run the entire base library.
We believe that this is an evidence that we caught a sizeable
part of the language features.

\subsection{Development Process}
\label{sec:library:development}

\todo{}

The base library was not added in one block.
Instead, we added which function were necessary
(the computational content of above).
The testing framework lead us to know which functions were to be implemented,
and as such served as a real-world case study for the framework.




\section{Related Work}
\label{sec:related:work}

% Few tools about R.
R is a notably difficult programming language~\parencite{RInferno},
whose semantics is constantly moving---%
see for instance the recent addition
of R's alternative representation~\parencite{altrepR}.
In our formalization, we chose to ignore these fast moving parts,
but these parts are used by real-world R programs.
Furthermore, the diversity of R users is such that different R programs
will use very different libraries and features,
as the generally accepted guideline~\parencite{RGuidelines}
does not restrain users about them.
This makes it difficult to build tools for R,
and as a consequence, relatively few tools for R exist
in comparison to the size of its community.

% Genthat.
In particular,
there exist few testing frameworks in R.
The testR~\parencite{maj2013testr, 2014testr} project,
which later evolved into the Genthat~\parencite{genthat} library,
is however based on an interesting way of generating unit tests for R functions.
It starts from a program using the functions to be tested.
It then annotates and executes this program,
storing the trace of the calls to the functions to be tested.
Unit tests are then generated from this trace.
The Genthat library is thus useful to generate tests for a library
given some program using it,
which can then be used to ensure that further versions of the library
do not break existing code.

% FastR
GNU~R is not the only R interpreter that exist.
Many existing interpreters are based on the same C core code,
but use different libraries for linear algebra,
usually optimized for a given usage.
%
The FastR~\parencite{kalibera2014fast} project takes a different approach
as it also reimplemented the core of the R interpreter.
It is based on the Truffle self-optimizing framework~\parencite{wuerthingertruffle}.
FastR is faster than the reference interpreter not only in the linear-algebraic part, but also in the language interpretation layer.
%
In both cases, a difference of behavior between GNU~R
and the specialized interpreter is considered as a bug.
We believe that this supports our choice of basing
our work on the GNU~R interpreter.

% JavaScript semantics and their trust sources.
To the best of our knowledge, we are the first to provide a mechanized specification of R. But the general goal of formalizing full real-world languages---%
as opposed to small subsets---is not new.
%
JavaScript is a particularly relevant example.
Indeed, empirical analyses
have confirmed that the language features
that are usually ignored in the formalised subsets of JavaScript
are actually important for actual web developers~\parencite{RichardsHBV11}.
%
In the case of JavaScript, there are several trust sources.
First, the language is precisely specified by the ECMAScript specification~\parencite{es2019}.
Second, there exist various test suites~\parencite{test262, mozillatests}
as well as several widely used interpreters.
As a consequence, various formal specifications of JavaScript exist,
each related with different of its trust sources.

% Maffeis et al.
The first full formal semantics of JavaScript~\parencite{aplas08}
is a semantics related to the third version of the ECMAScript specification.
It had a major influence on the definitions of further JavaScript formal
specifications~\parencite{ses, popl14jscert, popl12-Towards, usenix}.
It also served as the formal basis to prove the soundness of security-related
JavaScript subsets~\parencite{MMT-CSF-TR09, mmt-esorics09, mmt-oakland10}.
This work was however not mechanized, making it difficult to be used as a basis for other formalization work.

% The Essence of JavaScript.
In parallel, several formal semantics
for JavaScript were based on a JavaScript interpreter~\parencite{js-ml, Guha2010, Politz:S5, kjs}.
These semantics are related to JavaScript test suites,
either by comparing the results with the expected result,
or by comparing results with widely used JavaScript interpreters.
These formalizations tend to be easier to build
as testing frameworks already exist.
Furthermore, they are usually easier to understand by non-specialists.
However, such formalizations suffer from all the issues of test suites:
for instance, in JavaScript the \mintinline{javascript}{for}-\mintinline{javascript}{in} feature was then loosely tested,
and its behavior varied from interpreters to interpreters.

% JSCert.
The JSCert formalization~\parencite{popl14jscert}
is an interesting step forward as it was designed
to be related with both the ECMAScript specification and the JavaScript test suites.
The formalization is composed of two parts: a mechanized specification and an interpreter. The JSCert specification is syntactically related with the ECMAScript specification through an eyeball correspondence, and the interpreter passes its test suites.
The specification and the interpreter are related to each other by a Coq proof.
This double-relation provides a large amount of trust to JSCert.
In practice, both relations served to find issues in the JSCert specification,
but also some implementation bugs in other interpreters,
as well as mistakes in the ECMAScript specification.
Furthermore, JSCert is mechanized:
this facilitates its reuse for other projects.
However, this project involved 8 people for a year:
building both a specification and an interpreter,
as well as a correctness proof between them, involves a lot of resources.
In \CoqR, we solved this issue by defining the big-step operational semantics as an interpreter: the same definition is both executable and syntactically close to its specification (the GNU~R interpreter).

% CompCert.
The Coq proof assistant has already been used
in a variety of mechanized language formalization projects.
The most well-known is the CompCert project~\cite{Leroy-Compcert-CACM}, 
a verified optimizing compiler for C.
This compiler is proven to be free of compilation bugs,
leading to safer programs in critical software.
This project comes with a formalization of the C programming language,
as well as the formalizations of the intermediate compilation languages.
%
Due to the compilation nature of the CompCert project,
it was acceptable to restrict the behaviors of the C programming language
in their formalization,
restricting it to the behaviors that will actually be compiled by CompCert.
The Formalin project~\parencite{formalin} is another formalization
of the C language, which aims at precisely listing all the possible behaviors of a C program. 

\section{Conclusion and Future Work}
\label{sec:conclusion}

\todo{}

We have a fully trustable formalization of R.

This formalization can be used to prove program logic in R,
the amount of work for a direct approach being quite large.

We have a testing architecture that can be extended.

We believe our testing framework to be adaptable to other situations,
typically another programming language to be tested.

Our R specification is a shallow embedding of the reference interpreter of R.
Link with Formalin

\printbibliography{}

\end{document}

